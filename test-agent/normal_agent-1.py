#!/usr/bin/env python3
"""
Normal Agent (Baseline) - Uses LLM to analyze text for sarcasm and slang.
This baseline agent often fails on sarcasm detection.
Now integrated with HumanRPC SDK for automatic Human RPC when confidence is low.
"""

import json
import os
import sys
import time
import requests
from dotenv import load_dotenv
import google.generativeai as genai

# Add SDK to path for importing
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'main-app', 'sdk', 'src'))
from human_rpc_sdk import AutoAgent, guard, HumanVerificationError, SDKConfigurationError, PaymentError

# Load environment variables
load_dotenv()


def calculate_consensus_params(ai_certainty: float) -> dict:
    """
    Calculate consensus parameters using the same algorithm as the Human RPC API.
    This replicates the Inverse Confidence Sliding Scale algorithm.
    
    Args:
        ai_certainty: AI confidence level (0.5 to 1.0)
        
    Returns:
        Dictionary with requiredVoters and consensusThreshold
    """
    # Algorithm bounds (matching the Human RPC API)
    N_MIN = 3   # Minimum number of voters
    N_MAX = 15  # Maximum number of voters
    T_MIN = 0.51  # Minimum consensus threshold (51%)
    T_MAX = 0.90  # Maximum consensus threshold (90%)
    CERTAINTY_MIN = 0.5  # Minimum AI certainty
    CERTAINTY_MAX = 1.0  # Maximum AI certainty
    
    # Clamp certainty to valid range
    clamped_certainty = max(CERTAINTY_MIN, min(CERTAINTY_MAX, ai_certainty))
    
    # Calculate Uncertainty Factor (U)
    uncertainty = (1.0 - clamped_certainty) / (CERTAINTY_MAX - CERTAINTY_MIN)
    uncertainty = max(0, min(1, uncertainty))
    
    # Calculate Required Voters (N)
    raw_voters = N_MIN + int(uncertainty * (N_MAX - N_MIN) + 0.5)  # Round up
    voters = raw_voters + 1 if raw_voters % 2 == 0 else raw_voters  # Make odd to prevent ties
    required_voters = max(N_MIN, min(N_MAX, voters))
    
    # Calculate Consensus Threshold (T)
    consensus_threshold = T_MIN + (uncertainty * (T_MAX - T_MIN))
    consensus_threshold = max(T_MIN, min(T_MAX, consensus_threshold))
    
    return {
        "requiredVoters": required_voters,
        "consensusThreshold": consensus_threshold,
        "uncertaintyFactor": uncertainty
    }

# Initialize HumanRPC SDK with custom configuration for this agent
# The SDK auto-manages wallet creation and handles 402 Payment Required responses
agent = AutoAgent(
    network="devnet",  # Use devnet for testing, change to "mainnet-beta" for production
    timeout=30,  # Longer timeout for LLM processing
    default_agent_name="SarcasmDetector-v1",  # Custom agent name
    default_reward="0.4 USDC",  # Higher reward for sarcasm detection (complex task)
    default_reward_amount=0.4,  # Matching float value
    default_category="Sarcasm Detection",  # Specific category for this task
    default_escrow_amount="0.8 USDC"  # 2x reward as escrow (best practice)
)

# Confidence threshold for triggering Human RPC
CONFIDENCE_THRESHOLD = 0.80


def analyze_text(text: str) -> dict:
    """
    Analyze text for sentiment using LLM with manual human verification handling.
    This version allows us to start real-time polling immediately when Human RPC is triggered.
    
    Args:
        text: The text/query to analyze (user query)
        
    Returns:
        Dictionary with required fields:
        - userQuery: The original query/text
        - agentConclusion: What the agent thinks (e.g., "POSITIVE" or "NEGATIVE")
        - confidence: Confidence level (0.0-1.0)
        - reasoning: Why the agent thinks that (explanation of the analysis)
        - human_verdict: (optional) Human verification result if confidence was low
    """
    # Get Google API key
    google_api_key = os.getenv("GOOGLE_API_KEY")
    
    if not google_api_key:
        raise ValueError("Google API key not configured. Set GOOGLE_API_KEY in your environment.")
    
    # Configure Gemini
    genai.configure(api_key=google_api_key)
    
    # Build system prompt
    system_prompt = """You are an expert at analyzing crypto-twitter slang and detecting sentiment.
Analyze the given text and determine if it's POSITIVE or NEGATIVE sentiment.
Pay special attention to sarcasm, irony, and crypto-twitter slang terms.

IMPORTANT: Be conservative with confidence scores. If the text is ambiguous, unclear, or could be interpreted multiple ways, use a confidence score below 0.8. Only use high confidence (0.9+) for very clear, unambiguous sentiment.

Return ONLY valid JSON in this exact format:
{
  "sentiment": "POSITIVE" or "NEGATIVE",
  "confidence": 0.0-1.0,
  "reasoning": "A brief explanation of why you reached this conclusion, including any indicators of sarcasm, irony, or slang that influenced your decision"
}"""
    
    # Build a single prompt string using system prompt + user message
    prompt = f"{system_prompt}\n\nUSER: Analyze this text: {text}"
    
    # Initialize the model (can be overridden with GEMINI_MODEL env var)
    model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
    model = genai.GenerativeModel(model_name)
    
    # Generate content
    try:
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.3,
            }
        )
        
        # Extract response text
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        # Try to find JSON in the response
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}') + 1
        if start_idx >= 0 and end_idx > start_idx:
            json_str = response_text[start_idx:end_idx]
            result = json.loads(json_str)
            
            # Validate result structure
            if 'sentiment' not in result or 'confidence' not in result or 'reasoning' not in result:
                raise ValueError(f"Invalid response structure: {result}")
            
            # Return new structure with all 4 required fields
            return {
                "userQuery": text,
                "agentConclusion": result['sentiment'],
                "confidence": float(result['confidence']),
                "reasoning": result['reasoning']
            }
        else:
            raise ValueError(f"Could not parse JSON from response: {response_text}")
            
    except Exception as e:
        print(f"âš ï¸  Error in Gemini API call: {e}")
        raise ValueError(f"Failed to analyze text: {e}")


def handle_human_rpc_with_realtime_polling(ai_result: dict) -> dict:
    """
    Handle Human RPC with immediate real-time polling.
    This starts polling as soon as the task is created, not waiting for SDK completion.
    """
    confidence = ai_result.get("confidence", 1.0)
    
    # Show consensus parameters
    consensus_params = calculate_consensus_params(confidence)
    print()
    print("ğŸ§® THIS AGENT'S VOTING REQUIREMENTS:")
    print(f"   ğŸ¯ AI Confidence: {confidence:.3f}")
    print(f"   ğŸ‘¥ Required Voters: {consensus_params['requiredVoters']}")
    print(f"   ğŸ“Š Consensus Threshold: {consensus_params['consensusThreshold'] * 100:.1f}%")
    print(f"   ğŸ² Minimum Votes Needed: {int(consensus_params['requiredVoters'] * consensus_params['consensusThreshold']) + 1}")
    print()
    print("â³ Triggering Human RPC and starting real-time updates...")
    
    # Prepare context
    context = {
        "type": "ai_verification",
        "summary": f"Verify AI analysis from analyze_text. Confidence: {confidence:.3f}",
        "data": {
            "userQuery": ai_result["userQuery"],
            "agentConclusion": ai_result["agentConclusion"],
            "confidence": confidence,
            "reasoning": ai_result["reasoning"]
        }
    }
    
    # Start Human RPC in background thread
    import threading
    import concurrent.futures
    
    def call_human_rpc():
        try:
            return agent.ask_human_rpc(
                text=ai_result["userQuery"],
                agentName="SarcasmDetector-v1",
                reward="0.4 USDC",
                rewardAmount=0.4,
                category="Sarcasm Detection",
                escrowAmount="0.8 USDC",
                context=context
            )
        except Exception as e:
            print(f"\nâŒ Human RPC error: {e}")
            return None
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(call_human_rpc)
        
        # Give it a moment to create the task
        time.sleep(3)
        
        # Try to get the latest task ID
        try:
            response = requests.get("http://localhost:3000/api/v1/tasks", timeout=10)
            if response.status_code == 200:
                tasks = response.json()
                if tasks and len(tasks) > 0:
                    # Get the most recent task
                    latest_task = tasks[0]
                    task_id = latest_task.get("taskId")
                    
                    if task_id:
                        print(f"ğŸ“‹ Task created: {task_id}")
                        print("ğŸš€ Starting real-time voting updates...")
                        print()
                        
                        # Start real-time polling
                        stop_event = threading.Event()
                        poll_thread = threading.Thread(
                            target=lambda: poll_task_progress_continuous(task_id, max_duration_minutes=15),
                            args=()
                        )
                        poll_thread.start()
                        
                        # Wait for either polling to complete or Human RPC to finish
                        try:
                            human_result = future.result(timeout=900)  # 15 minutes max
                            stop_event.set()
                            poll_thread.join(timeout=5)
                            
                            if human_result:
                                print("\nâœ… Human RPC completed successfully!")
                                # Combine AI result with human verdict
                                combined_result = ai_result.copy()
                                combined_result["human_verdict"] = human_result
                                return combined_result
                            
                        except concurrent.futures.TimeoutError:
                            print("\nâ° Human RPC timeout - but polling may continue...")
                            stop_event.set()
                            poll_thread.join(timeout=5)
                    
        except Exception as e:
            print(f"âš ï¸  Could not start real-time polling: {e}")
            print("   Falling back to SDK polling...")
            human_result = future.result()
            if human_result:
                combined_result = ai_result.copy()
                combined_result["human_verdict"] = human_result
                return combined_result
    
    # Return original result if Human RPC failed
    return ai_result


def poll_task_progress_continuous(task_id: str, max_duration_minutes: int = 10) -> dict:
    """
    Continuously poll task progress to show real-time voting updates.
    Updates every 2 seconds and shows live voting progress.
    
    Args:
        task_id: The task ID to poll
        max_duration_minutes: Maximum time to poll in minutes
        
    Returns:
        Final task status with voting information
    """
    
    human_rpc_url = os.getenv("HUMAN_RPC_URL", "http://localhost:3000/api/v1/tasks")
    task_url = f"{human_rpc_url}/{task_id}"
    
    print("=" * 60)
    print(f"ğŸ”„ LIVE VOTING UPDATES - Task: {task_id}")
    print("=" * 60)
    print("   Updates every 2 seconds - Press Ctrl+C to stop")
    print()
    
    start_time = time.time()
    max_duration_seconds = max_duration_minutes * 60
    poll_count = 0
    last_vote_count = -1
    
    try:
        while True:
            poll_count += 1
            elapsed_time = time.time() - start_time
            
            # Check timeout
            if elapsed_time >= max_duration_seconds:
                print(f"â° Polling timeout after {max_duration_minutes} minutes")
                break
            
            try:
                response = requests.get(task_url, timeout=10)
                if response.status_code == 200:
                    task_data = response.json()
                    status = task_data.get("status", "unknown")
                    consensus_info = task_data.get("consensus", {})
                    
                    current_votes = consensus_info.get("currentVoteCount", 0)
                    required_votes = consensus_info.get("requiredVoters", 0)
                    yes_votes = consensus_info.get("yesVotes", 0)
                    no_votes = consensus_info.get("noVotes", 0)
                    consensus_threshold = consensus_info.get("consensusThreshold", 0.0)
                    ai_certainty = consensus_info.get("aiCertainty", 0.0)
                    
                    # Clear previous line and show current status
                    print(f"\rğŸ• {int(elapsed_time//60):02d}:{int(elapsed_time%60):02d} | ", end="")
                    
                    # Show voting progress
                    progress_pct = (current_votes / required_votes * 100) if required_votes > 0 else 0
                    progress_bar = "â–ˆ" * int(progress_pct // 5) + "â–‘" * (20 - int(progress_pct // 5))
                    
                    print(f"ğŸ“Š [{progress_bar}] {current_votes}/{required_votes} votes ({progress_pct:.1f}%)", end="")
                    
                    if yes_votes + no_votes > 0:
                        current_majority = max(yes_votes, no_votes) / (yes_votes + no_votes)
                        majority_leader = "YES" if yes_votes > no_votes else "NO"
                        print(f" | {majority_leader}: {current_majority*100:.1f}%", end="")
                    
                    # Show if new vote came in
                    if current_votes > last_vote_count and last_vote_count >= 0:
                        print(" ğŸ†• NEW VOTE!", end="")
                    
                    last_vote_count = current_votes
                    
                    # Check if completed
                    if status == "completed":
                        print("\n")
                        print("ğŸ‰" * 20)
                        print("ğŸ CONSENSUS REACHED!")
                        print("ğŸ‰" * 20)
                        
                        result = task_data.get("result", {})
                        if result:
                            decision = result.get("decision", "unknown")
                            consensus_data = result.get("consensus", {})
                            final_majority = consensus_data.get("majorityPercentage", 0) * 100
                            
                            print()
                            print("ğŸ“‹ FINAL RESULTS:")
                            print(f"   ğŸ¯ Decision: {decision.upper()}")
                            print(f"   ğŸ“Š Final Votes: {current_votes}/{required_votes}")
                            print(f"   âœ… Yes Votes: {yes_votes}")
                            print(f"   âŒ No Votes: {no_votes}")
                            print(f"   ğŸ“ˆ Final Majority: {final_majority:.1f}%")
                            print(f"   ğŸ¯ Required Threshold: {consensus_threshold*100:.1f}%")
                            print(f"   â±ï¸  Total Time: {int(elapsed_time//60):02d}:{int(elapsed_time%60):02d}")
                        
                        return task_data
                    
                    # Flush output for real-time display
                    sys.stdout.flush()
                    
                else:
                    print(f"\nâš ï¸  Poll failed: HTTP {response.status_code}")
                    break
                    
            except requests.exceptions.RequestException as e:
                print(f"\nâŒ Network error: {e}")
                print("   Retrying in 5 seconds...")
                time.sleep(5)
                continue
            except Exception as e:
                print(f"\nâŒ Poll error: {e}")
                break
            
            # Wait before next poll (2 seconds for real-time feel)
            time.sleep(2)
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Polling stopped by user")
        print(f"   Last known status: {current_votes}/{required_votes} votes")
    
    return {}


def main():
    """Main function to run the normal agent with integrated Human RPC support."""
    print("=" * 60)
    print("Normal Agent (Baseline) - Sarcasm & Slang Detector")
    print("Integrated with HumanRPC SDK for automatic Human RPC")
    print("=" * 60)
    print()
    print("This agent uses AI for initial analysis, then calls Human RPC")
    print(f"when confidence is below the threshold ({CONFIDENCE_THRESHOLD}).")
    print("The @guard decorator automatically handles the confidence check and Human RPC calls.")
    print()
    print("ğŸ§® Consensus Algorithm Info:")
    print("   â€¢ Lower AI confidence â†’ More voters required + Higher consensus threshold")
    print("   â€¢ Voters: 3-15 people (always odd number to prevent ties)")
    print("   â€¢ Threshold: 51%-90% agreement needed")
    print("   â€¢ Multi-phase voting: General â†’ Top 50% â†’ Top 10% if needed")
    print()

    
    # Test input designed to have moderate confidence (0.7-0.75) to trigger human verification
    test_text = "Not sure about this one."
    
    print(f"ğŸ“ Analyzing text: \"{test_text}\"")
    print()
    
    try:
        # Step 1: Run AI analysis
        ai_result = analyze_text(test_text)
        confidence = ai_result.get("confidence", 1.0)
        
        # Step 2: Check if Human RPC is needed and handle it with real-time polling
        if confidence < CONFIDENCE_THRESHOLD:
            result = handle_human_rpc_with_realtime_polling(ai_result)
        else:
            result = ai_result
        
        print()
        print("=" * 60)
        print("ğŸ“‹ Final Analysis Summary")
        print("=" * 60)
        print(json.dumps(result, indent=2))
        print()
        
        # Check if human verification was triggered
        has_human_verdict = "human_verdict" in result
        has_verification_error = "human_verification_error" in result
        conclusion = result.get("agentConclusion", "UNKNOWN")
        confidence = result.get("confidence", 1.0)
        
        # Show analysis results
        print(f"ğŸ¤– AI Analysis: {conclusion} (confidence: {confidence:.2f})")
        
        # Show final results
        if confidence < CONFIDENCE_THRESHOLD:
            print("ğŸ¤–â¡ï¸ğŸ‘¤ Human RPC was triggered due to low confidence")
        else:
            print("âœ… AI was confident enough - no human verification needed")
        
        # Show final results
        has_human_verdict = "human_verdict" in result
        if has_human_verdict:
            human_decision = result.get("human_verdict", {}).get("decision", "unknown")
            print(f"   ğŸ‘¤ Final human verdict: {human_decision}")
        
        print()
        print("ğŸ“‹ FINAL ANALYSIS:")
        final_conclusion = result.get("agentConclusion", "UNKNOWN")
        final_confidence = result.get("confidence", 1.0)
        print(f"   ğŸ¯ Conclusion: {final_conclusion}")
        print(f"   ğŸ“Š Confidence: {final_confidence:.3f}")
        if has_human_verdict:
            print(f"   ğŸ‘¤ Human Verified: Yes")
        
        # Show payment information if human verification occurred
        if has_human_verdict:
            print()
            print("ğŸ’° Payment Information:")
            print(f"   Reward: 0.4 USDC")
            print(f"   Escrow: 0.8 USDC")
            print(f"   Network: devnet")
            print(f"   Agent: SarcasmDetector-v1")
            
    except SDKConfigurationError as e:
        print(f"âŒ SDK Configuration Error: {e}")
        print("   Check your SOLANA_PRIVATE_KEY and other configuration.")
    except PaymentError as e:
        print(f"âŒ Payment Error: {e}")
        print("   This could be due to insufficient funds in your Solana wallet.")
        print(f"   Wallet address: {agent.wallet.get_public_key()}")
    except HumanVerificationError as e:
        print(f"âŒ Human verification failed: {e}")
        print("   This could be due to network issues or Human RPC API problems.")
    except Exception as e:
        print(f"âŒ Unexpected error during analysis: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Verify required environment variables
    required_env_vars = ["SOLANA_PRIVATE_KEY", "GOOGLE_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print("âŒ Missing required environment variables:")
        for var in missing_vars:
            print(f"   - {var}")
        print()
        print("Please set these environment variables:")
        print("   export SOLANA_PRIVATE_KEY='your_base58_private_key'")
        print("   export GOOGLE_API_KEY='your_google_api_key'")
        print()
        print("For SOLANA_PRIVATE_KEY, you can generate a devnet wallet at:")
        print("   https://solfaucet.com/")
        sys.exit(1)
    
    # Show configuration
    print("ğŸ”§ Agent Configuration:")
    print(f"   Network: {agent.network}")
    print(f"   Agent Name: {agent.default_agent_name}")
    print(f"   Reward: {agent.default_reward}")
    print(f"   Category: {agent.default_category}")
    print(f"   Escrow: {agent.default_escrow_amount}")
    print(f"   Confidence Threshold: {CONFIDENCE_THRESHOLD}")
    print(f"   Wallet: {agent.wallet.get_public_key()}")
    print()
    
    main()

