#!/usr/bin/env python3
"""
Normal Agent (Baseline) - Uses LLM to answer user questions.
This baseline agent provides answers to user questions and uses Human RPC when confidence is low.
Now integrated with HumanRPC SDK for automatic Human RPC when confidence is low.
"""

import json
import os
import sys
import time
import requests
from dotenv import load_dotenv
import google.generativeai as genai

# Add SDK to path for importing
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'main-app', 'sdk', 'src'))
from human_rpc_sdk import (
    AutoAgent, guard, HumanVerificationError, SDKConfigurationError, PaymentError,
    ReiteratorMaxAttemptsError, ReiteratorRateLimitError, ReiteratorConfigurationError
)

# Load environment variables
load_dotenv()


def calculate_consensus_params(ai_certainty: float) -> dict:
    """
    Calculate consensus parameters using the same algorithm as the Human RPC API.
    This replicates the Inverse Confidence Sliding Scale algorithm.
    
    Args:
        ai_certainty: AI confidence level (0.5 to 1.0)
        
    Returns:
        Dictionary with requiredVoters and consensusThreshold
    """
    # Algorithm bounds (matching the Human RPC API)
    N_MIN = 3   # Minimum number of voters
    N_MAX = 15  # Maximum number of voters
    T_MIN = 0.51  # Minimum consensus threshold (51%)
    T_MAX = 0.90  # Maximum consensus threshold (90%)
    CERTAINTY_MIN = 0.5  # Minimum AI certainty
    CERTAINTY_MAX = 1.0  # Maximum AI certainty
    
    # Clamp certainty to valid range
    clamped_certainty = max(CERTAINTY_MIN, min(CERTAINTY_MAX, ai_certainty))
    
    # Calculate Uncertainty Factor (U)
    uncertainty = (1.0 - clamped_certainty) / (CERTAINTY_MAX - CERTAINTY_MIN)
    uncertainty = max(0, min(1, uncertainty))
    
    # Calculate Required Voters (N)
    raw_voters = N_MIN + int(uncertainty * (N_MAX - N_MIN) + 0.5)  # Round up
    voters = raw_voters + 1 if raw_voters % 2 == 0 else raw_voters  # Make odd to prevent ties
    required_voters = max(N_MIN, min(N_MAX, voters))
    
    # Calculate Consensus Threshold (T)
    consensus_threshold = T_MIN + (uncertainty * (T_MAX - T_MIN))
    consensus_threshold = max(T_MIN, min(T_MAX, consensus_threshold))
    
    return {
        "requiredVoters": required_voters,
        "consensusThreshold": consensus_threshold,
        "uncertaintyFactor": uncertainty
    }

# Initialize HumanRPC SDK with custom configuration for this agent
# The SDK auto-manages wallet creation and handles 402 Payment Required responses
agent = AutoAgent(
    network="devnet",  # Use devnet for testing, change to "mainnet-beta" for production
    timeout=30,  # Longer timeout for LLM processing
    default_agent_name="QuestionAnswerer-v2",  # Custom agent name
    default_reward="0.4 USDC",  # Higher reward for question answering (complex task)
    default_reward_amount=0.4,  # Matching float value
    default_category="Question Answering",  # Specific category for this task
    default_escrow_amount="0.8 USDC",  # 2x reward as escrow (best practice)
    enable_session_management=True,  # Enable automatic session management
    heartbeat_interval=60,  # Send heartbeat every 60 seconds
    # Reiterator configuration for automatic retry on negative consensus
    reiterator=True,  # Enable automatic retry functionality
    max_retry_attempts=3,  # Maximum number of retry attempts
    backoff_strategy="exponential",  # Exponential backoff (1s, 2s, 4s...)
    base_delay=1.0  # Base delay in seconds between retries
)

# Confidence threshold for triggering Human RPC
# Set to 0.96 so that our 0.95 confidence test case still triggers Human RPC
# This creates the scenario: High AI confidence (0.95) â†’ Minimal voters (N=3)
# But still triggers Human RPC â†’ Potential for no consensus with minimal voters
CONFIDENCE_THRESHOLD = 0.96


def answer_question(text: str) -> dict:
    """
    Answer user questions using LLM with manual human verification handling.
    This version allows us to start real-time polling immediately when Human RPC is triggered.
    
    For the minimal voters test case, we override the AI analysis to return high confidence (0.95)
    which will result in minimal voters (N=3) and low consensus threshold (51%).
    
    Args:
        text: The user's question
        
    Returns:
        Dictionary with required fields:
        - userQuery: The original question
        - agentConclusion: The agent's answer to the question
        - confidence: Confidence level (0.0-1.0) in the answer's correctness
        - reasoning: Why the agent thinks this is the correct answer
        - human_verdict: (optional) Human verification result if confidence was low
    """
    # Special test case: Override for minimal voters scenario
    if "what is the capital of france" in text.lower():
        print("ğŸ¯ SPECIAL TEST CASE DETECTED: Overriding AI analysis for minimal voters scenario")
        print("   â€¢ Setting confidence to 0.95 (high) to get minimal voters (N=3)")
        print("   â€¢ But still below our threshold (0.96) to trigger Human RPC")
        print("   â€¢ This creates the edge case: minimal voters but potential for no consensus")
        return {
            "userQuery": text,
            "agentConclusion": "Paris",
            "confidence": 0.95,  # High confidence = minimal voters (N=3, T=51%)
            "reasoning": "Paris is the well-known capital of France. High confidence answer for minimal voters test case."
        }
    
    # Get Google API key
    google_api_key = os.getenv("GOOGLE_API_KEY")
    
    if not google_api_key:
        raise ValueError("Google API key not configured. Set GOOGLE_API_KEY in your environment.")
    
    # Configure Gemini
    genai.configure(api_key=google_api_key)
    
    # Build system prompt
    system_prompt = """You are a helpful AI assistant that answers user questions accurately and concisely.
Provide a clear, informative answer to the user's question.

IMPORTANT: Be conservative with confidence scores. If the question is complex, ambiguous, or requires specialized knowledge you're uncertain about, use a confidence score below 0.8. Only use high confidence (0.9+) for questions you can answer with high certainty.

Return ONLY valid JSON in this exact format:
{
  "answer": "Your clear and concise answer to the question",
  "confidence": 0.0-1.0,
  "reasoning": "A brief explanation of why you believe this answer is correct and how confident you are in it"
}"""
    
    # Build a single prompt string using system prompt + user message
    prompt = f"{system_prompt}\n\nUSER QUESTION: {text}"
    
    # Initialize the model (can be overridden with GEMINI_MODEL env var)
    model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
    model = genai.GenerativeModel(model_name)
    
    # Generate content
    try:
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.3,
            }
        )
        
        # Extract response text
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        # Try to find JSON in the response
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}') + 1
        if start_idx >= 0 and end_idx > start_idx:
            json_str = response_text[start_idx:end_idx]
            result = json.loads(json_str)
            
            # Validate result structure
            if 'answer' not in result or 'confidence' not in result or 'reasoning' not in result:
                raise ValueError(f"Invalid response structure: {result}")
            
            # Return new structure with all 4 required fields
            return {
                "userQuery": text,
                "agentConclusion": result['answer'],
                "confidence": float(result['confidence']),
                "reasoning": result['reasoning']
            }
        else:
            raise ValueError(f"Could not parse JSON from response: {response_text}")
            
    except Exception as e:
        print(f"âš ï¸  Error in Gemini API call: {e}")
        raise ValueError(f"Failed to answer question: {e}")


def handle_human_rpc_with_reiterator_support(ai_result: dict) -> dict:
    """
    Handle Human RPC with custom reiterator logic for our API response format.
    This implements manual retry logic since the SDK's reiterator doesn't recognize our API format.
    """
    confidence = ai_result.get("confidence", 1.0)
    
    # Show consensus parameters
    consensus_params = calculate_consensus_params(confidence)
    print()
    print("ğŸ§® THIS AGENT'S VOTING REQUIREMENTS:")
    print(f"   ğŸ¯ AI Confidence: {confidence:.3f}")
    print(f"   ğŸ‘¥ Required Voters: {consensus_params['requiredVoters']}")
    print(f"   ğŸ“Š Consensus Threshold: {consensus_params['consensusThreshold'] * 100:.1f}%")
    print(f"   ğŸ² Minimum Votes Needed: {int(consensus_params['requiredVoters'] * consensus_params['consensusThreshold']) + 1}")
    
    # Special messaging for minimal voters case
    if confidence >= 0.95:
        print()
        print("ğŸ¯ MINIMAL VOTERS SCENARIO ACTIVE:")
        print(f"   â€¢ High AI confidence ({confidence:.1%}) = Minimal voters ({consensus_params['requiredVoters']})")
        print(f"   â€¢ Low consensus threshold ({consensus_params['consensusThreshold']:.1%})")
        print("   â€¢ Even with minimal requirements, consensus may still fail!")
        print("   â€¢ Example: 1 Yes, 2 No = 66.7% majority but no consensus decision")
        print("   â€¢ This demonstrates the edge case where minimal voters â‰  guaranteed consensus")
    
    print()
    print("â³ Triggering Human RPC and starting real-time updates...")
    print("ğŸ”„ CUSTOM REITERATOR ACTIVE: Will retry if humans reject the answer")
    print("   â€¢ Negative consensus (consensus='no' or more NO votes) triggers retry")
    print("   â€¢ Up to 3 attempts with exponential backoff (1s, 2s, 4s...)")
    print("   â€¢ Each retry costs an additional 0.4 USDC")
    
    # Prepare context
    context = {
        "type": "ai_verification",
        "summary": f"Verify AI answer from answer_question. Confidence: {confidence:.3f}. REITERATOR TEST CASE.",
        "data": {
            "userQuery": ai_result["userQuery"],
            "agentConclusion": ai_result["agentConclusion"],
            "confidence": confidence,
            "reasoning": ai_result["reasoning"],
            "testCase": "reiterator_test_case"
        }
    }
    
    max_attempts = 3
    base_delay = 1.0
    
    for attempt in range(max_attempts):
        try:
            print(f"\nğŸ”„ Attempt {attempt + 1}/{max_attempts}")
            
            # Temporarily disable SDK reiterator to handle manually
            original_reiterator_enabled = agent.reiterator_enabled
            agent.disable_reiterator()
            
            try:
                # Call Human RPC
                human_result = agent.ask_human_rpc(
                    text=ai_result["userQuery"],
                    agentName="QuestionAnswerer-v2",
                    reward="0.4 USDC",
                    rewardAmount=0.4,
                    category="Question Answering",
                    escrowAmount="0.8 USDC",
                    context=context
                )
            finally:
                # Restore original reiterator state
                if original_reiterator_enabled:
                    agent.enable_reiterator()
            
            if not human_result:
                print("âŒ No result received")
                continue
            
            # Check if we should retry based on our API response format
            result_data = human_result.get("result", {})
            consensus = result_data.get("consensus", "unknown")
            final_votes = result_data.get("finalVotes", {})
            yes_votes = final_votes.get("yes", 0)
            no_votes = final_votes.get("no", 0)
            
            print(f"ğŸ“Š Voting Results: {yes_votes} YES, {no_votes} NO")
            print(f"ğŸ¯ Consensus: {consensus}")
            
            # Determine if this is a negative result that should trigger retry
            should_retry = (
                consensus == "no" or  # API says no consensus
                no_votes > yes_votes or  # More rejections than approvals
                (yes_votes == 0 and no_votes > 0)  # All rejections
            )
            
            if not should_retry or attempt == max_attempts - 1:
                # Either positive result or final attempt
                if should_retry:
                    print("âŒ FINAL ATTEMPT: No more retries available")
                    print("ğŸš« Humans consistently rejected the AI's answer")
                else:
                    print("âœ… Positive consensus achieved!")
                
                print("\nâœ… Human RPC completed!")
                # Combine AI result with human verdict
                combined_result = ai_result.copy()
                combined_result["human_verdict"] = human_result
                return combined_result
            
            # Negative result - prepare for retry
            print(f"ğŸ”„ Negative consensus detected - preparing retry...")
            
            if attempt < max_attempts - 1:
                # Calculate exponential backoff delay
                delay = base_delay * (2 ** attempt)
                print(f"â±ï¸  Waiting {delay:.1f}s before retry...")
                time.sleep(delay)
            
        except Exception as e:
            print(f"âŒ Attempt {attempt + 1} failed: {e}")
            if attempt == max_attempts - 1:
                print("ğŸš« All retry attempts exhausted")
                raise
            
            # Wait before retry on error
            delay = base_delay * (2 ** attempt)
            print(f"â±ï¸  Waiting {delay:.1f}s before retry...")
            time.sleep(delay)
    
    # This should not be reached
    print("âŒ Unexpected end of retry loop")
    return ai_result


def handle_human_rpc_with_realtime_polling(ai_result: dict) -> dict:
    """
    Handle Human RPC using the SDK's built-in polling.
    The SDK handles task creation and polling internally.
    
    For the minimal voters test case, this demonstrates the edge case where:
    - High AI confidence (0.95) results in minimal voters (N=3) and low threshold (51%)
    - But the voting pattern can still prevent consensus from being reached
    """
    confidence = ai_result.get("confidence", 1.0)
    
    # Show consensus parameters
    consensus_params = calculate_consensus_params(confidence)
    print()
    print("ğŸ§® THIS AGENT'S VOTING REQUIREMENTS:")
    print(f"   ğŸ¯ AI Confidence: {confidence:.3f}")
    print(f"   ğŸ‘¥ Required Voters: {consensus_params['requiredVoters']}")
    print(f"   ğŸ“Š Consensus Threshold: {consensus_params['consensusThreshold'] * 100:.1f}%")
    print(f"   ğŸ² Minimum Votes Needed: {int(consensus_params['requiredVoters'] * consensus_params['consensusThreshold']) + 1}")
    
    # Special messaging for minimal voters case
    if confidence >= 0.95:
        print()
        print("ğŸ¯ MINIMAL VOTERS SCENARIO ACTIVE:")
        print(f"   â€¢ High AI confidence ({confidence:.1%}) = Minimal voters ({consensus_params['requiredVoters']})")
        print(f"   â€¢ Low consensus threshold ({consensus_params['consensusThreshold']:.1%})")
        print("   â€¢ Even with minimal requirements, consensus may still fail!")
        print("   â€¢ Example: 1 Yes, 2 No = 66.7% majority but no consensus decision")
        print("   â€¢ This demonstrates the edge case where minimal voters â‰  guaranteed consensus")
    
    print()
    print("â³ Triggering Human RPC and starting real-time updates...")
    print("ğŸ”„ REITERATOR ACTIVE: Will automatically retry if humans reject the answer")
    print("   â€¢ Negative consensus triggers automatic retry")
    print("   â€¢ Up to 3 attempts with exponential backoff (1s, 2s, 4s...)")
    print("   â€¢ Each retry costs an additional 0.4 USDC")
    
    # Prepare context
    context = {
        "type": "ai_verification",
        "summary": f"Verify AI answer from answer_question. Confidence: {confidence:.3f}. MINIMAL VOTERS TEST CASE.",
        "data": {
            "userQuery": ai_result["userQuery"],
            "agentConclusion": ai_result["agentConclusion"],
            "confidence": confidence,
            "reasoning": ai_result["reasoning"],
            "testCase": "minimal_voters_no_consensus" if confidence >= 0.95 else "normal"
        }
    }
    
    try:
        # Call Human RPC - the SDK handles task creation and polling internally
        human_result = agent.ask_human_rpc(
            text=ai_result["userQuery"],
            agentName="QuestionAnswerer-v2",
            reward="0.4 USDC",
            rewardAmount=0.4,
            category="Question Answering",
            escrowAmount="0.8 USDC",
            context=context
        )
        
        if human_result:
            print("\nâœ… Human RPC completed successfully!")
            # Combine AI result with human verdict
            combined_result = ai_result.copy()
            combined_result["human_verdict"] = human_result
            return combined_result
        else:
            print("\nâŒ Human RPC failed or returned None")
            return ai_result
            
    except Exception as e:
        print(f"\nâŒ Human RPC error: {e}")
        return ai_result


def poll_task_progress_continuous(task_id: str, max_duration_minutes: int = 10) -> dict:
    """
    Continuously poll task progress to show real-time voting updates.
    Updates every 2 seconds and shows live voting progress.
    
    Args:
        task_id: The task ID to poll
        max_duration_minutes: Maximum time to poll in minutes
        
    Returns:
        Final task status with voting information
    """
    
    human_rpc_url = os.getenv("HUMAN_RPC_URL", "http://localhost:3000/api/v1/tasks")
    task_url = f"{human_rpc_url}/{task_id}"
    
    print("=" * 60)
    print(f"ğŸ”„ LIVE VOTING UPDATES - Task: {task_id}")
    print("=" * 60)
    print("   Updates every 2 seconds - Press Ctrl+C to stop")
    print()
    
    start_time = time.time()
    max_duration_seconds = max_duration_minutes * 60
    poll_count = 0
    last_vote_count = -1
    
    try:
        while True:
            poll_count += 1
            elapsed_time = time.time() - start_time
            
            # Check timeout
            if elapsed_time >= max_duration_seconds:
                print(f"â° Polling timeout after {max_duration_minutes} minutes")
                break
            
            try:
                response = requests.get(task_url, timeout=10)
                if response.status_code == 200:
                    task_data = response.json()
                    status = task_data.get("status", "unknown")
                    consensus_info = task_data.get("consensus", {})
                    
                    current_votes = consensus_info.get("currentVoteCount", 0)
                    required_votes = consensus_info.get("requiredVoters", 0)
                    yes_votes = consensus_info.get("yesVotes", 0)
                    no_votes = consensus_info.get("noVotes", 0)
                    consensus_threshold = consensus_info.get("consensusThreshold", 0.0)
                    ai_certainty = consensus_info.get("aiCertainty", 0.0)
                    
                    # Clear previous line and show current status
                    print(f"\rğŸ• {int(elapsed_time//60):02d}:{int(elapsed_time%60):02d} | ", end="")
                    
                    # Show voting progress
                    progress_pct = (current_votes / required_votes * 100) if required_votes > 0 else 0
                    progress_bar = "â–ˆ" * int(progress_pct // 5) + "â–‘" * (20 - int(progress_pct // 5))
                    
                    print(f"ğŸ“Š [{progress_bar}] {current_votes}/{required_votes} votes ({progress_pct:.1f}%)", end="")
                    
                    if yes_votes + no_votes > 0:
                        current_majority = max(yes_votes, no_votes) / (yes_votes + no_votes)
                        majority_leader = "YES" if yes_votes > no_votes else "NO"
                        print(f" | {majority_leader}: {current_majority*100:.1f}%", end="")
                    
                    # Show if new vote came in
                    if current_votes > last_vote_count and last_vote_count >= 0:
                        print(" ğŸ†• NEW VOTE!", end="")
                    
                    last_vote_count = current_votes
                    
                    # Check if completed
                    if status == "completed":
                        print("\n")
                        print("ğŸ‰" * 20)
                        print("ğŸ CONSENSUS REACHED!")
                        print("ğŸ‰" * 20)
                        
                        result = task_data.get("result", {})
                        if result:
                            decision = result.get("decision", "unknown")
                            consensus_data = result.get("consensus", {})
                            final_majority = consensus_data.get("majorityPercentage", 0) * 100
                            
                            print()
                            print("ğŸ“‹ FINAL RESULTS:")
                            print(f"   ğŸ¯ Decision: {decision.upper()}")
                            print(f"   ğŸ“Š Final Votes: {current_votes}/{required_votes}")
                            print(f"   âœ… Yes Votes: {yes_votes}")
                            print(f"   âŒ No Votes: {no_votes}")
                            print(f"   ğŸ“ˆ Final Majority: {final_majority:.1f}%")
                            print(f"   ğŸ¯ Required Threshold: {consensus_threshold*100:.1f}%")
                            print(f"   â±ï¸  Total Time: {int(elapsed_time//60):02d}:{int(elapsed_time%60):02d}")
                        
                        return task_data
                    
                    # Flush output for real-time display
                    sys.stdout.flush()
                    
                else:
                    print(f"\nâš ï¸  Poll failed: HTTP {response.status_code}")
                    break
                    
            except requests.exceptions.RequestException as e:
                print(f"\nâŒ Network error: {e}")
                print("   Retrying in 5 seconds...")
                time.sleep(5)
                continue
            except Exception as e:
                print(f"\nâŒ Poll error: {e}")
                break
            
            # Wait before next poll (2 seconds for real-time feel)
            time.sleep(2)
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Polling stopped by user")
        print(f"   Last known status: {current_votes}/{required_votes} votes")
    
    return {}


def main():
    """Main function to run the normal agent with integrated Human RPC support."""
    print("=" * 60)
    print("Normal Agent (Baseline) - Question Answering Assistant")
    print("Integrated with HumanRPC SDK for automatic Human RPC")
    print("=" * 60)
    print()
    print("This agent uses AI to answer questions, then calls Human RPC")
    print(f"when confidence is below the threshold ({CONFIDENCE_THRESHOLD}).")
    print("The @guard decorator automatically handles the confidence check and Human RPC calls.")
    print()
    print("ğŸ§® Consensus Algorithm Info:")
    print("   â€¢ Lower AI confidence â†’ More voters required + Higher consensus threshold")
    print("   â€¢ Voters: 3-15 people (always odd number to prevent ties)")
    print("   â€¢ Threshold: 51%-90% agreement needed")
    print("   â€¢ Multi-phase voting: General â†’ Top 50% â†’ Top 10% if needed")
    print()
    print("ğŸ¯ SPECIAL TEST CASE: Minimal Voters with No Consensus")
    print("   â€¢ This test is designed to trigger high AI confidence (95%)")
    print("   â€¢ Results in minimal voters (N=3) and low threshold (51%)")
    print("   â€¢ But voting pattern prevents consensus from being reached")
    print("   â€¢ Demonstrates edge case where even minimal requirements fail")
    print()
    print("ğŸ”„ REITERATOR FUNCTIONALITY:")
    print("   â€¢ Automatic retry enabled when humans reject AI's answer")
    print("   â€¢ Will retry up to 3 times with exponential backoff")
    print("   â€¢ Continues until positive consensus or max attempts reached")
    print("   â€¢ Each retry incurs additional costs (0.4 USDC per attempt)")
    print()

    
    # Test input designed to have HIGH confidence (0.95) to get minimal voters (N=3)
    # but still trigger human verification due to our threshold being 0.96
    test_text = "What is the capital of France?"
    
    print(f"â“ Answering question: \"{test_text}\"")
    print()
    
    try:
        # Step 1: Run AI analysis
        ai_result = answer_question(test_text)
        confidence = ai_result.get("confidence", 1.0)
        
        # Step 2: Check if Human RPC is needed and handle it with real-time polling
        if confidence < CONFIDENCE_THRESHOLD:
            # Show initial reiterator status
            reiterator_status = agent.get_reiterator_status()
            print(f"ğŸ”„ Reiterator Status Before Task:")
            print(f"   Session Retries So Far: {reiterator_status.get('total_retries_session', 0)}")
            
            result = handle_human_rpc_with_reiterator_support(ai_result)
            
            # Show final reiterator status
            final_reiterator_status = agent.get_reiterator_status()
            print(f"\nğŸ”„ Reiterator Status After Task:")
            print(f"   Total Session Retries: {final_reiterator_status.get('total_retries_session', 0)}")
            retries_this_task = final_reiterator_status.get('total_retries_session', 0) - reiterator_status.get('total_retries_session', 0)
            print(f"   Retries This Task: {retries_this_task}")
        else:
            result = ai_result
        
        print()
        print("=" * 60)
        print("ğŸ“‹ Final Answer Summary")
        print("=" * 60)
        print(json.dumps(result, indent=2))
        print()
        
        # Check if human verification was triggered
        has_human_verdict = "human_verdict" in result
        has_verification_error = "human_verification_error" in result
        conclusion = result.get("agentConclusion", "UNKNOWN")
        confidence = result.get("confidence", 1.0)
        
        # Show analysis results
        print(f"ğŸ¤– AI Answer: {conclusion} (confidence: {confidence:.2f})")
        
        # Show final results
        if confidence < CONFIDENCE_THRESHOLD:
            print("ğŸ¤–â¡ï¸ğŸ‘¤ Human RPC was triggered due to confidence below threshold")
            if confidence >= 0.95:
                print("   ğŸ¯ SPECIAL CASE: High AI confidence (0.95) but still triggered Human RPC")
                print("   ğŸ“Š This creates minimal voters (N=3) scenario with potential for no consensus")
        else:
            print("âœ… AI was confident enough - no human verification needed")
        
        # Show final results
        has_human_verdict = "human_verdict" in result
        if has_human_verdict:
            human_verdict = result.get("human_verdict", {})
            human_decision = human_verdict.get("decision", "unknown")
            consensus_reached = human_verdict.get("result", {}).get("consensus", "no") == "yes"
            final_votes = human_verdict.get("result", {}).get("finalVotes", {})
            yes_votes = final_votes.get("yes", 0)
            no_votes = final_votes.get("no", 0)
            
            print(f"   ğŸ‘¤ Human Voting Results: {yes_votes} YES, {no_votes} NO")
            print(f"   ğŸ‘¤ Final human verdict: {human_decision}")
            
            if not consensus_reached:
                print("   âš ï¸  NO CONSENSUS REACHED - This demonstrates the minimal voters edge case!")
                print("   ğŸ“Š Even with minimal voters, consensus can still fail")
                if no_votes > yes_votes:
                    print("   ğŸš« Majority of humans REJECTED the AI's answer")
        
        print()
        print("ğŸ“‹ FINAL ANSWER:")
        
        # Determine the final answer based on human verdict
        if has_human_verdict:
            human_verdict = result.get("human_verdict", {})
            human_decision = human_verdict.get("decision", "unknown")
            consensus_reached = human_verdict.get("result", {}).get("consensus", "no") == "yes"
            final_votes = human_verdict.get("result", {}).get("finalVotes", {})
            yes_votes = final_votes.get("yes", 0)
            no_votes = final_votes.get("no", 0)
            
            if consensus_reached:
                # Humans reached positive consensus
                final_answer = result.get("agentConclusion", "UNKNOWN")
                print(f"   ğŸ¯ Answer: {final_answer}")
                print(f"   âœ… Human Consensus: YES ({yes_votes} accept, {no_votes} reject)")
                print(f"   ğŸ‘¤ Status: APPROVED - Humans verified the AI's answer")
            else:
                # No consensus reached
                final_answer = result.get("agentConclusion", "UNKNOWN")
                print(f"   ğŸ¯ AI Answer: {final_answer}")
                print(f"   âŒ Human Consensus: NO ({no_votes} reject, {yes_votes} accept)")
                print(f"   âš ï¸  Final Status: DISPUTED - No human consensus reached")
        else:
            # No human verification
            final_answer = result.get("agentConclusion", "UNKNOWN")
            print(f"   ğŸ¯ Answer: {final_answer}")
        
        final_confidence = result.get("confidence", 1.0)
        print(f"   ğŸ“Š AI Confidence: {final_confidence:.3f}")
        
        # Show payment information if human verification occurred
        if has_human_verdict:
            print()
            print("ğŸ’° Payment Information:")
            print(f"   Reward: 0.4 USDC")
            print(f"   Escrow: 0.8 USDC")
            print(f"   Network: devnet")
            print(f"   Agent: QuestionAnswerer-v2")
            
    except ReiteratorMaxAttemptsError as e:
        print(f"âŒ Reiterator Max Attempts Reached: {e}")
        print("   All retry attempts have been exhausted.")
        print("   The humans consistently rejected the AI's answer.")
        reiterator_status = agent.get_reiterator_status()
        print(f"   Total attempts made: {reiterator_status.get('total_retries_session', 0) + 1}")
    except ReiteratorRateLimitError as e:
        print(f"âŒ Reiterator Rate Limit Error: {e}")
        print("   Rate limiting encountered during retry attempts.")
    except ReiteratorConfigurationError as e:
        print(f"âŒ Reiterator Configuration Error: {e}")
        print("   Check your reiterator configuration parameters.")
    except SDKConfigurationError as e:
        print(f"âŒ SDK Configuration Error: {e}")
        print("   Check your SOLANA_PRIVATE_KEY and other configuration.")
    except PaymentError as e:
        print(f"âŒ Payment Error: {e}")
        print("   This could be due to insufficient funds in your Solana wallet.")
        print(f"   Wallet address: {agent.wallet.get_public_key()}")
    except HumanVerificationError as e:
        print(f"âŒ Human verification failed: {e}")
        print("   This could be due to network issues or Human RPC API problems.")
    except Exception as e:
        print(f"âŒ Unexpected error during question answering: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Verify required environment variables
    required_env_vars = ["SOLANA_PRIVATE_KEY", "GOOGLE_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print("âŒ Missing required environment variables:")
        for var in missing_vars:
            print(f"   - {var}")
        print()
        print("Please set these environment variables:")
        print("   export SOLANA_PRIVATE_KEY='your_base58_private_key'")
        print("   export GOOGLE_API_KEY='your_google_api_key'")
        print()
        print("For SOLANA_PRIVATE_KEY, you can generate a devnet wallet at:")
        print("   https://solfaucet.com/")
        sys.exit(1)
    
    # Show configuration
    print("ğŸ”§ Agent Configuration:")
    print(f"   Network: {agent.network}")
    print(f"   Agent Name: {agent.default_agent_name}")
    print(f"   Reward: {agent.default_reward}")
    print(f"   Category: {agent.default_category}")
    print(f"   Escrow: {agent.default_escrow_amount}")
    print(f"   Confidence Threshold: {CONFIDENCE_THRESHOLD}")
    print(f"   Wallet: {agent.wallet.get_public_key()}")
    
    # Show reiterator status
    reiterator_status = agent.get_reiterator_status()
    print(f"   ğŸ”„ Reiterator: {'Enabled' if reiterator_status['enabled'] else 'Disabled'}")
    if reiterator_status['enabled']:
        print(f"   ğŸ“Š Max Attempts: {reiterator_status.get('max_attempts', 'N/A')}")
        print(f"   â±ï¸  Backoff Strategy: {reiterator_status.get('backoff_strategy', 'N/A')}")
        print(f"   ğŸ• Base Delay: {reiterator_status.get('base_delay', 'N/A')}s")
    print()
    
    main()

